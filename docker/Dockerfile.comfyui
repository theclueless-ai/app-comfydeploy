# Custom ComfyUI Dockerfile for RunPod Serverless - Vellum 2.0
# This Dockerfile contains all custom nodes and models required for the Vellum upscaling workflow
#
# Build and push to your container registry:
#   docker build -f docker/Dockerfile.comfyui -t your-registry/comfyui-vellum:latest .
#   docker push your-registry/comfyui-vellum:latest
#
# Then configure your RunPod serverless endpoint to use this image
# IMPORTANT: Attach a Network Volume to persist models between cold starts

FROM runpod/worker-comfyui:5.1.0-base

# Environment variables
ENV PYTHONUNBUFFERED=1
ENV COMFYUI_PATH=/comfyui

# ============================================================================
# CUSTOM NODES INSTALLATION
# ============================================================================

# rgthree-comfy - Advanced node utilities and workflow helpers
RUN comfy-node-install rgthree-comfy

# ComfyUI-KJNodes - Collection of useful nodes (GrowMaskWithBlur, etc.)
RUN comfy-node-install comfyui-kjnodes

# comfyui-deploy - Deployment and external input/output nodes
RUN comfy-node-install comfyui-deploy

# ComfyUI_UltimateSDUpscale - Ultimate SD Upscale for high-quality image upscaling
RUN comfy-node-install comfyui-ultimatesdupscale

# Masquerade Nodes - Mask manipulation (Cut By Mask, etc.)
RUN comfy-node-install masquerade-nodes-comfyui

# ComfyUI ArtVenture - Art and image processing (ColorCorrect, etc.)
RUN comfy-node-install comfyui-art-venture

# ComfyUI-mxToolkit - Utility nodes (mxSlider, etc.)
RUN comfy-node-install comfyui-mxtoolkit

# ComfyUI-post-processing-nodes - Post-processing effects (FilmGrain, etc.)
RUN comfy-node-install comfyui-post-processing-nodes

# WAS Node Suite - Comprehensive node collection (Text to Number, etc.)
RUN comfy-node-install was-node-suite-comfyui

# LF Nodes - Math operations (LF_MathOperation, etc.)
RUN comfy-node-install lf-nodes

# ComfyUI-DyPE - Dynamic Positional Encoding for FLUX (DyPE_FLUX node)
RUN comfy-node-install comfyui-dype

# ComfyUI_FaceParsing - Face parsing for mask generation
# (FaceParsingLoader, FaceParsingInfer, FacePartMask nodes)
WORKDIR /comfyui/custom_nodes
RUN git clone https://github.com/Bwebbfx/ComfyUI_FaceParsing.git && \
    cd ComfyUI_FaceParsing && \
    if [ -f requirements.txt ]; then pip install --no-cache-dir -r requirements.txt; fi

# Return to root
WORKDIR /

# ============================================================================
# MODEL DOWNLOAD SCRIPT - Uses RunPod Network Volume for persistence
# ============================================================================
# The network volume is mounted at /runpod-volume
# Models are stored there and symlinked to /comfyui/models
# This ensures models persist between cold starts and are only downloaded once

RUN echo '#!/bin/bash\n\
set -e\n\
echo "ðŸ“¦ Setting up models from Network Volume..."\n\
\n\
# Check if network volume is mounted\n\
if [ ! -d "/runpod-volume" ]; then\n\
    echo "âš ï¸ Network volume not mounted at /runpod-volume"\n\
    echo "   Models will be downloaded to local storage (slower cold starts)"\n\
    MODELS_DIR="/comfyui/models"\n\
else\n\
    echo "âœ… Network volume detected"\n\
    MODELS_DIR="/runpod-volume/models"\n\
    \n\
    # Create directory structure on network volume\n\
    mkdir -p "$MODELS_DIR/checkpoints"\n\
    mkdir -p "$MODELS_DIR/unet"\n\
    mkdir -p "$MODELS_DIR/loras/Vellum"\n\
    mkdir -p "$MODELS_DIR/upscale_models"\n\
    mkdir -p "$MODELS_DIR/vae"\n\
    mkdir -p "$MODELS_DIR/clip"\n\
    \n\
    # Create symlink so ComfyUI uses network volume models\n\
    rm -rf /comfyui/models 2>/dev/null || true\n\
    ln -sfn "$MODELS_DIR" /comfyui/models\n\
    echo "âœ… Symlink created: /comfyui/models -> $MODELS_DIR"\n\
fi\n\
\n\
# Function to download file if not exists or too small\n\
download_model() {\n\
    local url="$1"\n\
    local dest="$2"\n\
    local min_size="${3:-1000000}"  # Default 1MB minimum\n\
    local auth_header="$4"\n\
    \n\
    if [ -f "$dest" ]; then\n\
        local file_size=$(stat -c%s "$dest" 2>/dev/null || echo 0)\n\
        if [ "$file_size" -gt "$min_size" ]; then\n\
            echo "âœ… $(basename $dest) already exists ($(numfmt --to=iec $file_size))"\n\
            return 0\n\
        else\n\
            echo "âš ï¸ $(basename $dest) too small, re-downloading..."\n\
            rm -f "$dest"\n\
        fi\n\
    fi\n\
    \n\
    echo "ðŸ“¥ Downloading $(basename $dest)..."\n\
    if [ -n "$auth_header" ]; then\n\
        wget --progress=bar:force:noscroll --header="$auth_header" -O "$dest" "$url" || {\n\
            echo "âŒ Failed to download $(basename $dest)"\n\
            rm -f "$dest"\n\
            return 1\n\
        }\n\
    else\n\
        wget --progress=bar:force:noscroll -O "$dest" "$url" || {\n\
            echo "âŒ Failed to download $(basename $dest)"\n\
            rm -f "$dest"\n\
            return 1\n\
        }\n\
    fi\n\
    echo "âœ… Downloaded $(basename $dest)"\n\
}\n\
\n\
# ============================================================================\n\
# 1. FLUX UNET MODEL (~12GB)\n\
# ============================================================================\n\
FLUX_FILE="$MODELS_DIR/unet/flux1-dev.safetensors"\n\
if [ -n "$FLUX_UNET_URL" ]; then\n\
    download_model "$FLUX_UNET_URL" "$FLUX_FILE" 10000000000\n\
elif [ -n "$HF_TOKEN" ]; then\n\
    download_model \\\n\
        "https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/flux1-dev.safetensors" \\\n\
        "$FLUX_FILE" 10000000000 "Authorization: Bearer $HF_TOKEN"\n\
else\n\
    echo "âš ï¸ FLUX model not configured. Set FLUX_UNET_URL or HF_TOKEN (requires HF access)"\n\
fi\n\
\n\
# ============================================================================\n\
# 2. CHECKPOINT: CyberRealistic XL v8.0 (~6GB)\n\
# ============================================================================\n\
CHECKPOINT_FILE="$MODELS_DIR/checkpoints/cyberrealisticXL_v80.safetensors"\n\
if [ -n "$CHECKPOINT_URL" ]; then\n\
    download_model "$CHECKPOINT_URL" "$CHECKPOINT_FILE" 5000000000\n\
else\n\
    echo "âš ï¸ Checkpoint not configured. Set CHECKPOINT_URL"\n\
    echo "   Download from Civitai: https://civitai.com/models/547084"\n\
fi\n\
\n\
# ============================================================================\n\
# 3. CLIP/TEXT ENCODERS\n\
# ============================================================================\n\
# T5 XXL FP16 (~10GB)\n\
T5_FILE="$MODELS_DIR/clip/t5xxl_fp16.safetensors"\n\
if [ ! -f "$T5_FILE" ] || [ $(stat -c%s "$T5_FILE" 2>/dev/null || echo 0) -lt 9000000000 ]; then\n\
    echo "ðŸ“¥ Downloading T5 XXL encoder..."\n\
    download_model \\\n\
        "https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp16.safetensors" \\\n\
        "$T5_FILE" 9000000000\n\
else\n\
    echo "âœ… T5 XXL encoder already exists"\n\
fi\n\
\n\
# CLIP L (~250MB)\n\
CLIP_FILE="$MODELS_DIR/clip/clip_l.safetensors"\n\
if [ ! -f "$CLIP_FILE" ]; then\n\
    echo "ðŸ“¥ Downloading CLIP L encoder..."\n\
    download_model \\\n\
        "https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/clip_l.safetensors" \\\n\
        "$CLIP_FILE" 200000000\n\
else\n\
    echo "âœ… CLIP L encoder already exists"\n\
fi\n\
\n\
# ============================================================================\n\
# 4. VAE: FLUX AE (~300MB)\n\
# ============================================================================\n\
VAE_FILE="$MODELS_DIR/vae/ae.safetensors"\n\
if [ ! -f "$VAE_FILE" ]; then\n\
    echo "ðŸ“¥ Downloading FLUX VAE..."\n\
    download_model \\\n\
        "https://huggingface.co/black-forest-labs/FLUX.1-schnell/resolve/main/ae.safetensors" \\\n\
        "$VAE_FILE" 200000000\n\
else\n\
    echo "âœ… FLUX VAE already exists"\n\
fi\n\
\n\
# ============================================================================\n\
# 5. UPSCALE MODELS\n\
# ============================================================================\n\
# 4xFaceUpDAT (~70MB)\n\
UPSCALE_DAT="$MODELS_DIR/upscale_models/4xFaceUpDAT.safetensors"\n\
if [ -n "$UPSCALE_DAT_URL" ]; then\n\
    download_model "$UPSCALE_DAT_URL" "$UPSCALE_DAT" 50000000\n\
else\n\
    download_model \\\n\
        "https://huggingface.co/Phips/4xFaceUpDAT/resolve/main/4xFaceUpDAT.safetensors" \\\n\
        "$UPSCALE_DAT" 50000000 || \\\n\
    echo "âš ï¸ 4xFaceUpDAT not found. Set UPSCALE_DAT_URL or upload manually"\n\
fi\n\
\n\
# 1xSkinContrast-High-SuperUltraCompact (~1MB)\n\
SKIN_CONTRAST="$MODELS_DIR/upscale_models/1xSkinContrast-High-SuperUltraCompact.pth"\n\
if [ -n "$SKIN_CONTRAST_URL" ]; then\n\
    download_model "$SKIN_CONTRAST_URL" "$SKIN_CONTRAST" 100000\n\
else\n\
    download_model \\\n\
        "https://huggingface.co/Kim2091/AnimeSharp/resolve/main/1xSkinContrast-High-SuperUltraCompact.pth" \\\n\
        "$SKIN_CONTRAST" 100000 || \\\n\
    echo "âš ï¸ 1xSkinContrast not found. Set SKIN_CONTRAST_URL or upload manually"\n\
fi\n\
\n\
# ============================================================================\n\
# 6. LORA: Skin Texture\n\
# ============================================================================\n\
LORA_FILE="$MODELS_DIR/loras/Vellum/skintexture.safetensors"\n\
if [ -n "$LORA_SKINTEXTURE_URL" ]; then\n\
    download_model "$LORA_SKINTEXTURE_URL" "$LORA_FILE" 1000000\n\
elif [ -n "$HF_TOKEN" ]; then\n\
    download_model \\\n\
        "https://huggingface.co/g0tman1/skintexture.safetensors/resolve/main/skintexture.safetensors" \\\n\
        "$LORA_FILE" 1000000 "Authorization: Bearer $HF_TOKEN" || \\\n\
    echo "âš ï¸ LoRA skintexture failed. Check HF_TOKEN or set LORA_SKINTEXTURE_URL"\n\
else\n\
    echo "âš ï¸ LoRA skintexture not configured."\n\
    echo "   Set LORA_SKINTEXTURE_URL or HF_TOKEN environment variable"\n\
fi\n\
\n\
# ============================================================================\n\
# SUMMARY\n\
# ============================================================================\n\
echo ""\n\
echo "========================================"\n\
echo "ðŸ“‚ MODELS SUMMARY"\n\
echo "========================================"\n\
echo ""\n\
echo "ðŸ”· UNET (FLUX):"\n\
ls -lah "$MODELS_DIR/unet/" 2>/dev/null || echo "   (empty)"\n\
echo ""\n\
echo "ðŸ“¦ Checkpoints:"\n\
ls -lah "$MODELS_DIR/checkpoints/" 2>/dev/null || echo "   (empty)"\n\
echo ""\n\
echo "ðŸ“ CLIP/Text Encoders:"\n\
ls -lah "$MODELS_DIR/clip/" 2>/dev/null || echo "   (empty)"\n\
echo ""\n\
echo "ðŸŽ¨ VAE:"\n\
ls -lah "$MODELS_DIR/vae/" 2>/dev/null || echo "   (empty)"\n\
echo ""\n\
echo "ðŸ”¼ Upscale Models:"\n\
ls -lah "$MODELS_DIR/upscale_models/" 2>/dev/null || echo "   (empty)"\n\
echo ""\n\
echo "âœ¨ LoRAs:"\n\
ls -lah "$MODELS_DIR/loras/Vellum/" 2>/dev/null || echo "   (empty)"\n\
echo ""\n\
echo "========================================"\n\
echo "âœ… Model setup complete"\n\
echo "========================================"\n\
' > /setup_models.sh && chmod +x /setup_models.sh

# ============================================================================
# STARTUP SCRIPT
# ============================================================================
RUN echo '#!/bin/bash\n\
set -e\n\
echo "ðŸš€ Starting Vellum 2.0 ComfyUI Worker..."\n\
\n\
# Setup models from network volume\n\
/setup_models.sh\n\
\n\
# Start ComfyUI (the base image handles this, but we can customize if needed)\n\
echo "âœ… Ready to process requests"\n\
' > /custom_start.sh && chmod +x /custom_start.sh

# The base image (runpod/worker-comfyui) handles the actual startup
# Our setup script will be called during container initialization
